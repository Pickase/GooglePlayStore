{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ea28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.py\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "\n",
    "class Config(BaseModel):\n",
    "    play_csv: Path = Field(..., description=\"Path to Google Play CSV\")\n",
    "    ios_csv: Path = Field(..., description=\"Path to Apple Store CSV\")\n",
    "    random_state: int = 42\n",
    "    test_size: float = 0.3\n",
    "    n_jobs: int = -1\n",
    "\n",
    "# ── Logging Setup ─────────────────────────────────────────────────────────────\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# ── Data Loading & Validation ─────────────────────────────────────────────────\n",
    "\n",
    "def load_data(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    logging.info(f\"Loaded {len(df):,} rows from {path.name}\")\n",
    "    return df\n",
    "\n",
    "# ── Preprocessing Pipeline ────────────────────────────────────────────────────\n",
    "\n",
    "def build_preprocessor(numerical_cols, categorical_cols):\n",
    "    num_pipeline = Pipeline([\n",
    "        (\"impute_mean\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scale\", StandardScaler()),\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        (\"impute_const\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_cols),\n",
    "        (\"cat\", cat_pipeline, categorical_cols),\n",
    "    ], remainder=\"drop\")\n",
    "    return preprocessor\n",
    "\n",
    "# ── Modeling ──────────────────────────────────────────────────────────────────\n",
    "\n",
    "def evaluate_models(X, y, preprocessor, config: Config):\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=config.random_state, n_jobs=config.n_jobs),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=config.random_state),\n",
    "    }\n",
    "    results = {}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=config.random_state)\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline([\n",
    "            (\"preproc\", preprocessor),\n",
    "            (\"clf\", model),\n",
    "        ])\n",
    "        scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"f1_weighted\", n_jobs=config.n_jobs)\n",
    "        results[name] = scores\n",
    "        logging.info(f\"{name} F1-weighted CV: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "    return results\n",
    "\n",
    "# ── Main Workflow ─────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        config = Config(\n",
    "            play_csv=Path(\"googleplaystore.csv\"),\n",
    "            ios_csv=Path(\"AppleStore.csv\"),\n",
    "        )\n",
    "    except ValidationError as e:\n",
    "        logging.error(\"Configuration error:\\n%s\", e)\n",
    "        return\n",
    "\n",
    "    # Load and merge datasets if needed; here illustrate Play store only\n",
    "    df = load_data(config.play_csv)\n",
    "    # Filter to English and free apps\n",
    "    df = df[df[\"Type\"] == \"Free\"].copy()\n",
    "    df = df[df[\"App\"].str.encode(\"ascii\", errors=\"ignore\").str.len() - df[\"App\"].str.len().abs() <= 3]\n",
    "    # Drop duplicates, missing target\n",
    "    df.drop_duplicates(subset=[\"App\"], inplace=True)\n",
    "    df.dropna(subset=[\"Rating\", \"Reviews\", \"Category\"], inplace=True)\n",
    "\n",
    "    # Feature & target\n",
    "    df[\"Reviews\"] = df[\"Reviews\"].astype(int)\n",
    "    df[\"Installs\"] = df[\"Installs\"].str.replace(r\"[+,]\", \"\", regex=True).astype(int)\n",
    "    df[\"Price\"] = df[\"Price\"].astype(float)\n",
    "    X = df[[\"Rating\", \"Reviews\", \"Installs\", \"Price\", \"Category\", \"Content Rating\"]]\n",
    "    y = df[\"Genres\"]  # or other binary target\n",
    "\n",
    "    numerical_cols = [\"Rating\", \"Reviews\", \"Installs\", \"Price\"]\n",
    "    categorical_cols = [\"Category\", \"Content Rating\"]\n",
    "\n",
    "    preprocessor = build_preprocessor(numerical_cols, categorical_cols)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=config.test_size, stratify=y, random_state=config.random_state\n",
    "    )\n",
    "\n",
    "    # Evaluate models\n",
    "    evaluate_models(X_train, y_train, preprocessor, config)\n",
    "\n",
    "    # Final fit and report\n",
    "    final_pipe = Pipeline([\n",
    "        (\"preproc\", preprocessor),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=200, random_state=config.random_state, n_jobs=config.n_jobs)),\n",
    "    ])\n",
    "    final_pipe.fit(X_train, y_train)\n",
    "    y_pred = final_pipe.predict(X_test)\n",
    "    logging.info(\"Final Confusion Matrix:\\n%s\", confusion_matrix(y_test, y_pred))\n",
    "    logging.info(\"Final Classification Report:\\n%s\", classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef96191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# After training your best model (for example, Random Forest)\n",
    "best_model = classifiers['Random Forest']\n",
    "joblib.dump(best_model, 'model.h5')\n",
    "print(\"Saved trained model to model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "print(\"Saved Keras model to model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
